{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"SONA_NLP_Python\"\n",
        "---"
      ],
      "id": "1aab16a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "This paper critically analyzes the State of the Nation Address (SONA) speeches delivered by various South African presidents from 1994 to 2023. The primary objective is to categorize each president based on single sentences extracted from their respective SONA speeches. The study unfolds in XXX main sections.\n",
        "\n",
        "Initially, a concise literature review is presented, with emphasis on the domain of Natural Language Processing (NLP), particularly focusing on classification tasks within NLP. This review lays the groundwork for the methodologies and approaches applied in later sections of the paper.\n",
        "\n",
        "Subsequent sections offer an in-depth exploration and meticulous cleaning of the data utilized in the study. The exploration phase scrutinizes the dataset's balance and analyzes the vocabulary used, both overall and by each specific president. These preliminary steps are crucial for ensuring the integrity and reliability of the study's findings.\n",
        "\n",
        "The paper then transitions to a detailed exposition of the methodologies employed in the study. The methods section elucidates the three feature extraction tools deployed: Bag of Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), and Word Tokenization. Additionally, it describes the XXX predictive models applied, namely Gradient Boosted Trees, Feed Forward Neural Networks, and Support Vector Machines. Each tool and model is presented with a rationale for its inclusion and an explanation of its contribution to the study's objectives.\n",
        "\n",
        "Following the methods section, the paper presents and succinctly discusses the study's results. This section provides an initial interpretation of the findings, preparing the ground for the more in-depth analysis that follows.\n",
        "\n",
        "In the penultimate section, a comprehensive discussion of the results is provided. This discussion delves into the insights gleaned from the findings, offering detailed interpretations and drawing connections with the literature reviewed earlier. This section aims not only to shed light on the study's findings but also to locate these within the broader academic discourse on the subject.\n",
        "\n",
        "Finally, the paper concludes with a reflective overview of the study as a whole. This concluding section evaluates the study's successes and limitations, reflects on its contributions to the field, and suggests avenues for future research and exploration. Through this reflective lens, the paper not only summarizes its findings but also invites further scholarly engagement with the questions and challenges raised during the study.\n",
        "\n",
        "# Literature Review\n",
        "\n",
        "# Methods\n",
        "\n",
        "The methods applies fall into XXX main categoriis that also follows the workflow of the project. More specifically, data pre-processing, feature extraction, modellinig and model evaluation.\n",
        "\n",
        "## Data Pre-Processing\n",
        "In the data preprocessing phase prior to feature extraction, initial data loading was accomplished from text files, with each file containing SONA speeches from different South African presidents from 1994 to 2023. Files were filtered to ensure they were valid, and the president’s names were extracted and cleaned for later use. The speeches within each file were tokenized into sentences using the NLTK library, and any unnecessary newline characters within these sentences were removed. Each sentence was then associated with the relevant president, resulting in a structured data frame containing each sentence alongside its corresponding president’s name. Following this, the data underwent exploratory data analysis (EDA) where sentences associated with specific presidents were filtered out, and sentence lengths were calculated and visualized. The sentences were further cleaned by removing stop words (common words that do not contribute to the meaning of a sentence), and then grouped by president. Subsequently, the cleaned sentences were used for generating word clouds for visual inspection. Furthermore the most common words across all presidents were calculated and the average words per sentence was computed and plotted for each preesident.\n",
        "\n",
        "\n",
        "## Feature Extraction\n",
        "\n",
        "\n",
        "### Bag of Words (BoW)\n",
        "   The Bag of Words (BoW) method represents text data as a matrix of token (typically words) occurrence within a given document. Each row of the matrix corresponds to a document, while each column represents a unique token in the dataset. The matrix cell contains the count of occurrences of the token in the document. In mathematical terms, for a set of  $n$ documents $D$ and a set of $m$ unique tokens $T$, the BoW matrix $M$ is a $n \\times m$ matrix where $M_{ij}$ is the frequency of token $j$ in document $i$. For the dataset in question, each sentence from the president’s speeches is treated as a document. The BoW model tokenizes each sentence into words, creating a matrix that reflects the frequency count of each word within each sentence, yielding a sparse matrix representation of the word distribution in each president's speech.\n",
        "\n",
        "### Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "   The Term Frequency-Inverse Document Frequency (TF-IDF) technique assigns a weight to each term in a document reflecting its importance in the document relative to the entire corpus. The TF-IDF value of a term $t$ in a document $d$ within a corpus $D$ is computed as $\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)$, where $\\text{TF}(t, d)$ is the frequency of term $t$ in document $d$ divided by the total number of terms in $d$, and $\\text{IDF}(t, D)$ is the logarithm of the total number of documents in $D$ divided by the number of documents containing term $t$. In the context of the dataset, TF-IDF is calculated for each term in every sentence, resulting in a vector of TF-IDF values for each sentence, thereby emphasizing terms that are distinctive to specific speeches or presidents.\n",
        "\n",
        "### Word Embeddings\n",
        "Sentences from the presidential speeches dataset are tokenized into words. These tokens are then fed into the Word2Vec model, which learns vector representations for each word by predicting the context in which a word appears, effectively capturing the semantic relationships between words.Upon training Word2Vec with the tokenized sentences, each word is represented as a high-dimensional vector. To form a representative vector for a complete sentence, the word vectors within each sentence are averaged. This results in a single vector per sentence, encapsulating the semantic essence of the sentence based on its constituent words.\n",
        "\n",
        "These sentence-level vectors serve as the dataset's numerical features, providing a semantically rich representation of the sentences for subsequent machine learning applications in the project. Each vector not only represents its sentence but also mirrors the inherent semantic structure and relationships within the text, offering a meaningful feature set for analysis.By employing these methods, the raw textual data from the speeches is transformed into a numerical format suitable for training machine learning models, with each technique capturing different aspects and nuances of the data's structure and semantics.\n",
        "\n",
        "## Modelling \n",
        "\n",
        "Note that for each of the following predictive models, each of the three feature extraction methods detailed above are applied.\n",
        "\n",
        "### Gradient Boosted Trees\n",
        "\n",
        "Gradient Boosting is a general technique where models are built sequentially, with each new model being trained to correct the mistakes of the combined ensemble of existing models. This process is iteratively repeated, progressively improving the model’s accuracy until further improvements are negligible.\n",
        "\n",
        "Gradient Boosted Trees (GBTs) inherently leverage an ensemble methodology, combining the predictive power of multiple weak learners, in decision trees, to craft a more accurate and robust model. The algorithm incrementally builds an ensemble of trees where each subsequent tree compensates for the errors of the aggregate set of preceding trees. Through this iterative refinement, the algorithm not only enhances its precision but also avoids overfitting, providing a reliable generalization to unseen data.\n",
        "\n",
        "In our deployment of GBTs, using Yandex's CatBoost, careful parameter tuning was essential for optimized performance. We engaged 500 boosting iterations, a 0.05 learning rate, and a tree depth of 10. The boosting iterations define the number of trees in the model, with each iteration adding a new tree that corrects the errors of the ensemble. The learning rate, alternatively known as shrinkage, moderates the influence of each tree, preventing any single tree from dominating the ensemble prediction. The tree depth, meanwhile, influences the model's complexity, with deeper trees allowing for the capture of more complex patterns in the data but at the risk of overfitting. These parameters were selected after running a grid search over hyperparameters choosing the hyperaamters which minimised validation error computed using 5-fold cross validation.\n",
        "\n",
        "### Support Vector Machines\n"
      ],
      "id": "794258fe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install nltk requests matplotlib seaborn sklearn scikit-learn wordcloud catboost tensorflow gensim"
      ],
      "id": "52c7257e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install wordcloud"
      ],
      "id": "28f08eeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install gensim"
      ],
      "id": "c2fde4f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install tensorflow==2.14.0"
      ],
      "id": "b2786db2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install keras==2.14.0"
      ],
      "id": "3a33a4f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# General imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# NLTK imports\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Visualization imports\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# Preprocessing imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS, TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Model selection imports\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Machine learning model imports\n",
        "from sklearn.svm import SVC\n",
        "from catboost import CatBoostClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from catboost import Pool, cv, CatBoostClassifier\n",
        "\n",
        "# Word embedding imports\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Metrics import\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "id": "f02f8640",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "folder_path = 'speeches'  # Ensure this is your correct folder path\n",
        "files = os.listdir(folder_path)\n",
        "files = sorted([file for file in files if os.path.isfile(os.path.join(folder_path, file)) and file.endswith('.txt')])\n",
        "\n",
        "president_names = []\n",
        "\n",
        "# Updated regex pattern to handle more cases\n",
        "pattern = r'_(.+?)\\.txt'  # Non-greedy match to get the president name\n",
        "\n",
        "for file in files:\n",
        "    match = re.search(pattern, file)\n",
        "    if match:\n",
        "        president_name = match.group(1)\n",
        "        # Remove the \"_2\" suffix from the president names here\n",
        "        cleaned_president_name = president_name.replace('_2', '')\n",
        "        president_names.append(cleaned_president_name)\n",
        "    else:\n",
        "        print(f\"Warning: No match found in filename: {file}\")\n",
        "        president_names.append('Unknown')  # Placeholder for missing names\n",
        "\n",
        "# Check the lengths of files and president_names lists\n",
        "if len(files) != len(president_names):\n",
        "    print(f\"Warning: Number of files ({len(files)}) does not match number of president names ({len(president_names)})\")\n",
        "\n",
        "# Initialize dataframe with appropriate column names\n",
        "df = pd.DataFrame(columns=['Presidents', 'Sentences'])\n",
        "\n",
        "# Iterate over all files and extract sentences\n",
        "for file_index in range(len(files)):\n",
        "    file_path = os.path.join(folder_path, files[file_index])\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()[2:]  # Adjust if your files have a different structure\n",
        "\n",
        "    text = ' '.join(lines)\n",
        "    sentences = sent_tokenize(text)\n",
        "    cleaned_sentences = [sentence.replace('\\n', '') for sentence in sentences]\n",
        "\n",
        "    current_president = president_names[file_index]\n",
        "    dftemp = pd.DataFrame({'Presidents': [current_president] * len(cleaned_sentences), 'Sentences': cleaned_sentences})\n",
        "    df = pd.concat([df, dftemp], axis=0, ignore_index=True)\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "#df.to_csv('finalSentence.csv', index=False)"
      ],
      "id": "8de463e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = pd.read_csv(\"finalSentence.csv\")"
      ],
      "id": "1e7b2518",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA\n"
      ],
      "id": "1b8ad38d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set the style of the visualization\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Group the data by president and count the number of sentences for each\n",
        "sentence_counts = data['Presidents'].value_counts()\n",
        "\n",
        "# Create a bar plot of the number of sentences per president\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=sentence_counts.index, y=sentence_counts.values, palette=\"viridis\")\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Presidents')\n",
        "plt.ylabel('Number of Sentences')\n",
        "plt.title('Number of Sentences per President')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "id": "8a6aef3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = data[data['Presidents'] != ' Motlanthe']\n",
        "data = data[data['Presidents'] != 'deKlerk']"
      ],
      "id": "7dc03e69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the length in words of each sentence\n",
        "data['Sentence_Length'] = data['Sentences'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Group by president and calculate the average sentence length\n",
        "average_length = data.groupby('Presidents')['Sentence_Length'].mean().sort_values(ascending=False)\n",
        "\n",
        "palette = sns.color_palette(\"viridis\", n_colors=len(sentence_counts))\n",
        "\n",
        "# Create a mapping of president to color based on the order in sentence_counts\n",
        "color_mapping = {president: palette[i] for i, president in enumerate(sentence_counts.index)}\n",
        "\n",
        "# Get colors for the presidents in the order of average_length\n",
        "bar_colors = [color_mapping[president] for president in average_length.index]\n",
        "\n",
        "# Create a bar plot of the average sentence length per president with consistent colors\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=average_length.index, y=average_length.values, palette=bar_colors)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Presidents')\n",
        "plt.ylabel('Average Sentence Length (in words)')\n",
        "plt.title('Average Sentence Length per President')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "id": "355c6813",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Overall top Words used\n",
        "\n",
        "blah blah blah\n",
        "# Word Cloud per president\n"
      ],
      "id": "229fe261"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define a function to remove stop words from a sentence\n",
        "def remove_stopwords(sentence):\n",
        "    words = sentence.split()\n",
        "    cleaned_words = [word for word in words if word.lower() not in STOPWORDS]\n",
        "    return ' '.join(cleaned_words)\n",
        "\n",
        "# Apply the function to remove stop words from each sentence in the DataFrame\n",
        "data['Cleaned_Sentences'] = data['Sentences'].apply(remove_stopwords)\n",
        "\n",
        "# Group the cleaned sentences by president\n",
        "grouped = data.groupby('Presidents')['Cleaned_Sentences'].apply(' '.join).reset_index()\n",
        "\n",
        "# Initialize a dictionary to store word clouds for each president\n",
        "wordclouds = {}\n",
        "\n",
        "# Generate a word cloud for each president\n",
        "for index, row in grouped.iterrows():\n",
        "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(row['Cleaned_Sentences'])\n",
        "    wordclouds[row['Presidents']] = wordcloud\n",
        "\n",
        "# Display the word clouds\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, (president, wordcloud) in enumerate(wordclouds.items(), 1):\n",
        "    plt.subplot(2, 2, i)  # Adjusted subplot arrangement to 2x2 grid\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(president)\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "id": "4472044a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bag of Words + Data Split\n",
        "\n",
        "ayo\n"
      ],
      "id": "5a888123"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocess text data: lowercasing and removing punctuation\n",
        "data['Processed_Sentences'] = data['Sentences'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
        "\n",
        "# Extract relevant columns\n",
        "text_data = data['Processed_Sentences']\n",
        "y = data['Presidents']\n",
        "\n",
        "# Initialize a CountVectorizer for BOW representation with stop words removal\n",
        "vectorizer = CountVectorizer(lowercase=True, token_pattern=r\"(?u)\\b\\w+\\b\", stop_words='english')\n",
        "\n",
        "# Fit and transform the text data\n",
        "X = vectorizer.fit_transform(text_data)\n",
        "\n",
        "# Encode the class labels\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
      ],
      "id": "3896e24f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Boosted Tree CatBoost\n",
        "\n",
        "\n",
        "Here looks like 56.18 percent accuracy\n"
      ],
      "id": "90298f2b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pool = Pool(data=X_train, label=y_train, cat_features=[])\n",
        "# Parameters for the CatBoostClassifier\n",
        "params = {\n",
        "    'iterations': 3000,          # Number of boosting iterations\n",
        "    'depth': 5,                # Depth of the trees\n",
        "    'learning_rate': 0.05,      # Learning rate\n",
        "    'loss_function': 'MultiClass',  # Objective function\n",
        "    'random_seed': 42,             # Random seed\n",
        "    'verbose': 10                   # Output training information every 10 iterations\n",
        "}\n",
        "\n",
        "#cv_results = cv(\n",
        " #   pool=pool,\n",
        " #   params=params,\n",
        " #   fold_count=5,  # Number of folds in CV\n",
        " #   plot=False,   # Set to True if you want to see the plot of train and test errors during cross-validation\n",
        " #   early_stopping_rounds=10\n",
        "#)\n",
        "\n",
        "# Save cross-validation results to a CSV file\n",
        "#cv_results.to_csv('cv_results_over_epochs.csv', index=False)\n",
        "\n",
        "# Train the model on the full training set and save it\n",
        "#clf = CatBoostClassifier(**params)\n",
        "#clf.fit(pool)\n",
        "#clf.save_model('catboost_BOW.cbm')\n",
        "\n",
        "# Load the model from the file\n",
        "loaded_model = CatBoostClassifier()\n",
        "loaded_model.load_model('catboost_BOW.cbm')\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_decoded = le.inverse_transform(y_pred.flatten().astype(int))\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred.flatten().astype(int))\n",
        "classification_rep = classification_report(y_test, y_pred.flatten().astype(int), target_names=le.classes_)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print('Classification Report:')\n",
        "print(classification_rep)"
      ],
      "id": "10c6cfdc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the CSV file\n",
        "new_df = pd.read_csv(\"cv_results_over_epochs.csv\")\n",
        "\n",
        "# Plotting the mean values for training and validation errors with distinct colors\n",
        "plt.plot(new_df['iterations'], new_df['train-MultiClass-mean'], label='Training Error', color='b')  # 'b' stands for blue\n",
        "plt.plot(new_df['iterations'], new_df['test-MultiClass-mean'], label='Validation Error', color='r')  # 'r' stands for red\n",
        "\n",
        "# Adding title and labels to the plot\n",
        "plt.title('Training and Validation Error Over Epochs')\n",
        "plt.xlabel('Epochs (Iterations)')\n",
        "plt.ylabel('Error')\n",
        "\n",
        "# Adding legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "e0936857",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Network\n",
        "Accuracy: 60.41%"
      ],
      "id": "9254328f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Convert the sparse matrix to dense matrix as neural network needs dense input\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Define 5-fold cross-validation\n",
        "#num_folds = 5\n",
        "#kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "\n",
        "# Initialize variables to store sum of accuracies for each epoch\n",
        "#sum_train_accuracy = []\n",
        "#sum_val_accuracy = []\n",
        "\n",
        "#for train, test in kfold.split(X_train_dense, y_train):\n",
        "    # Split data into train and validation sets for this fold\n",
        " #   X_train_fold, X_val_fold = X_train_dense[train], X_train_dense[test]\n",
        " #   y_train_fold, y_val_fold = y_train[train], y_train[test]\n",
        "\n",
        "    # Define model (adjust as necessary)\n",
        "  #  model = Sequential([\n",
        "   #     Dense(505, input_dim=X_train_fold.shape[1], activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-8)),\n",
        "   #     Dense(220, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-7)),\n",
        "   #     Dense(len(np.unique(y_train)), activation='softmax')\n",
        "   # ])\n",
        "    \n",
        "    # Compile model (adjust optimizer, loss, and metrics as necessary)\n",
        "   # model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train model and store training history\n",
        "    #history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=20)\n",
        "\n",
        "    # Append accuracies for each epoch for this fold\n",
        "    #sum_train_accuracy.append(history.history['accuracy'])\n",
        "    #sum_val_accuracy.append(history.history['val_accuracy'])\n",
        "\n",
        "# Compute average accuracies for each epoch\n",
        "#avg_train_accuracy = np.mean(sum_train_accuracy, axis=0)\n",
        "#avg_val_accuracy = np.mean(sum_val_accuracy, axis=0)\n",
        "\n",
        "# Save averaged accuracies to CSV\n",
        "#avg_accuracies_df = pd.DataFrame({'avg_train_accuracy': avg_train_accuracy, 'avg_val_accuracy': avg_val_accuracy})\n",
        "#avg_accuracies_df.to_csv('avg_accuracies_over_epochs_NN_1.csv', index=False)\n",
        "\n",
        "# Load averaged accuracies from CSV\n",
        "loaded_avg_accuracies = pd.read_csv('avg_accuracies_over_epochs_NN_1.csv')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, len(loaded_avg_accuracies['avg_train_accuracy']) + 1), loaded_avg_accuracies['avg_train_accuracy'], label='Average Training Accuracy')\n",
        "plt.plot(range(1, len(loaded_avg_accuracies['avg_val_accuracy']) + 1), loaded_avg_accuracies['avg_val_accuracy'], label='Average Validation Accuracy', linestyle='dashed')\n",
        "\n",
        "plt.title('Average Training and Validation Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(1, len(loaded_avg_accuracies['avg_train_accuracy']) + 1))  # Adjust x-axis ticks to start from 1\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "id": "862bf295",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Val accurcay 58.80%"
      ],
      "id": "1d0b8eb2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train = X_train.toarray()\n",
        "X_test = X_test.toarray()\n",
        "\n",
        "# Define model\n",
        "#model = Sequential([\n",
        "#    Dense(505, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-8)),  # Input layer\n",
        "#    Dense(220, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-7)),  # Hidden layer\n",
        "#    Dense(len(label_mapping), activation='softmax')  # Output layer\n",
        "#])\n",
        "\n",
        "# Compile model\n",
        "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#epochs = 2\n",
        "#model.fit(X_train, y_train, validation_split=0.2, epochs=epochs)\n",
        "\n",
        "# Save the final model\n",
        "#model.save('NN_final_model_1.h5')\n",
        "\n",
        "# Load the final model\n",
        "loaded_model = load_model('NN_final_model_1.h5')\n",
        "\n",
        "\n",
        "# Evaluate the loaded model on the test set\n",
        "final_loss, final_accuracy = loaded_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {final_loss:.4f}')\n",
        "print(f'Test Accuracy: {final_accuracy*100:.2f}%')"
      ],
      "id": "c389a1ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM\n"
      ],
      "id": "f88b8b69"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],  # Type of SVM\n",
        "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
        "#}\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "#svm = SVC(random_state=42)\n",
        "\n",
        "# Initialize Grid Search\n",
        "#grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform Grid Search on the training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best estimator from Grid Search\n",
        "#best_params = grid_search.best_params_\n",
        "#best_svm_clf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions using the best model\n",
        "#y_pred_best_svm = best_svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "#accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
        "#classification_rep_best_svm = classification_report(y_test, y_pred_best_svm)\n",
        "\n",
        "#best_params, accuracy_best_svm, classification_rep_best_svm"
      ],
      "id": "85bd0786",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize the Support Vector Machine classifier\n",
        "svm_clf = SVC(kernel='linear', gamma = 'scale', C = 0.1, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(f'test score {accuracy_svm}')"
      ],
      "id": "dd753520",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TF-IDF\n"
      ],
      "id": "7ab8337c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize a TfidfVectorizer with stop words removal\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Compute the TF-IDF values for each word in each sentence\n",
        "X = vectorizer.fit_transform(data['Sentences'])\n",
        "\n",
        "# Encode the president names as target variable\n",
        "y = data['Presidents']\n",
        "\n",
        "# Split the data into training and testing sets with an 80-20 ratio\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Display the shapes of the resulting training and testing sets\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "id": "f2f985f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Catboost\n",
        "\n",
        "55.68\n"
      ],
      "id": "d34c4561"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit and transform the training data\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "\n",
        "# Transform the testing data\n",
        "y_test_encoded = le.transform(y_test)\n",
        "\n",
        "# Create pool with training data\n",
        "pool = Pool(data=X_train, label=y_train_encoded, cat_features=[])\n",
        "\n",
        "# Parameters for CatBoostClassifier\n",
        "params = {\n",
        "    'iterations': 3000,\n",
        "    'depth': 5,\n",
        "    'learning_rate': 0.05,\n",
        "    'loss_function': 'MultiClass',\n",
        "    'random_seed': 42,\n",
        "    'verbose': 10\n",
        "}\n",
        "\n",
        "# Perform cross-validation and save results\n",
        "#cv_results = cv(\n",
        "#    pool=pool,\n",
        "#    params=params,\n",
        "#    fold_count=5,\n",
        "#    plot=False,\n",
        "#    early_stopping_rounds=10\n",
        "#)\n",
        "\n",
        "# Save cross-validation results to a CSV file\n",
        "#cv_results.to_csv('cv_results_over_epochs_2.csv', index=False)\n",
        "\n",
        "# Train model on full training set and save it\n",
        "#clf = CatBoostClassifier(**params)\n",
        "#clf.fit(pool)\n",
        "#clf.save_model('catboost_TFIDF.cbm')\n",
        "\n",
        "# Load model from file\n",
        "loaded_model = CatBoostClassifier()\n",
        "loaded_model.load_model('catboost_TFIDF.cbm')\n",
        "\n",
        "# Make predictions on testing data\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_class = y_pred.flatten().astype(int)\n",
        "\n",
        "# Inverse transform the predictions back to original labels\n",
        "y_pred_decoded = le.inverse_transform(y_pred_class)\n",
        "\n",
        "# Evaluate the classifier using the original (non-encoded) labels\n",
        "accuracy = accuracy_score(y_test_encoded, y_pred_class)\n",
        "classification_rep = classification_report(y_test_encoded, y_pred_class, target_names=le.classes_)\n",
        "\n",
        "# Print accuracy and classification report\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print('Classification Report:')\n",
        "print(classification_rep)"
      ],
      "id": "ba78cbed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the CSV file\n",
        "new_df = pd.read_csv(\"cv_results_over_epochs_2.csv\")\n",
        "\n",
        "# Plotting the mean values for training and validation errors with distinct colors\n",
        "plt.plot(new_df['iterations'], new_df['train-MultiClass-mean'], label='Training Error', color='b')  \n",
        "plt.plot(new_df['iterations'], new_df['test-MultiClass-mean'], label='Validation Error', color='r')  \n",
        "\n",
        "# Adding title and labels to the plot\n",
        "plt.title('Training and Validation Error Over Epochs')\n",
        "plt.xlabel('Epochs (Iterations)')\n",
        "plt.ylabel('Error')\n",
        "\n",
        "# Adding legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "8be505d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM\n",
        "\n",
        "\n",
        "grid search SVM\n",
        "\n",
        "best params:\n",
        "10, 'gamma': 'scale', 'kernel': 'rbf'\n"
      ],
      "id": "da4b8d39"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],  # Type of SVM\n",
        "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
        "#}\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "#svm = SVC(random_state=42)\n",
        "\n",
        "# Initialize Grid Search\n",
        "#grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform Grid Search on the training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best estimator from Grid Search\n",
        "#best_params = grid_search.best_params_\n",
        "#best_svm_clf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions using the best model\n",
        "#y_pred_best_svm = best_svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "#accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
        "#classification_rep_best_svm = classification_report(y_test, y_pred_best_svm)\n",
        "\n",
        "#best_params, accuracy_best_svm, classification_rep_best_svm"
      ],
      "id": "af3f8813",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize the Support Vector Machine classifier\n",
        "svm_clf = SVC(kernel='rbf', gamma = 'scale', C = 10, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_svm = svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "accuracy_svm"
      ],
      "id": "947add24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neural Net\n"
      ],
      "id": "1c87730b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Convert the sparse matrix to dense matrix as neural network needs dense input\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "#seed = 7\n",
        "#np.random.seed(seed)\n",
        "\n",
        "# Define 5-fold cross-validation\n",
        "#num_folds = 5\n",
        "#kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
        "\n",
        "# Initialize variables to store sum of accuracies for each epoch\n",
        "#sum_train_accuracy = []\n",
        "#sum_val_accuracy = []\n",
        "\n",
        "#for train, test in kfold.split(X_train_dense, y_train):\n",
        "    # Split data into train and validation sets for this fold\n",
        "#    X_train_fold, X_val_fold = X_train_dense[train], X_train_dense[test]\n",
        "#    y_train_fold, y_val_fold = y_train[train], y_train[test]\n",
        "\n",
        "#    model = Sequential([\n",
        "#        Dense(505, input_dim=X_train_fold.shape[1], activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-8)),\n",
        "#        Dense(220, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-7)),\n",
        "#        Dense(len(np.unique(y_train)), activation='softmax')\n",
        "#    ])\n",
        "    \n",
        "#    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # Train model and store training history\n",
        "#    history = model.fit(X_train_fold, y_train_fold, validation_data=(X_val_fold, y_val_fold), epochs=20)\n",
        "\n",
        "    # Append accuracies for each epoch for this fold\n",
        "#    sum_train_accuracy.append(history.history['accuracy'])\n",
        "#    sum_val_accuracy.append(history.history['val_accuracy'])\n",
        "\n",
        "# Compute average accuracies for each epoch\n",
        "#avg_train_accuracy = np.mean(sum_train_accuracy, axis=0)\n",
        "#avg_val_accuracy = np.mean(sum_val_accuracy, axis=0)\n",
        "\n",
        "# Save averaged accuracies to CSV\n",
        "#avg_accuracies_df = pd.DataFrame({'avg_train_accuracy': avg_train_accuracy, 'avg_val_accuracy': avg_val_accuracy})\n",
        "#avg_accuracies_df.to_csv('avg_accuracies_over_epochs_NN_2.csv', index=False)\n",
        "\n",
        "# Load averaged accuracies from CSV\n",
        "loaded_avg_accuracies = pd.read_csv('avg_accuracies_over_epochs_NN_2.csv')\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, len(loaded_avg_accuracies['avg_train_accuracy']) + 1), loaded_avg_accuracies['avg_train_accuracy'], label='Average Training Accuracy')\n",
        "plt.plot(range(1, len(loaded_avg_accuracies['avg_val_accuracy']) + 1), loaded_avg_accuracies['avg_val_accuracy'], label='Average Validation Accuracy', linestyle='dashed')\n",
        "\n",
        "plt.title('Average Training and Validation Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(1, len(loaded_avg_accuracies['avg_train_accuracy']) + 1))  # Adjust x-axis ticks to start from 1\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "id": "69cf6719",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test Accuracy: 59.58%"
      ],
      "id": "82d28f91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#X_train = X_train.toarray()\n",
        "#X_test = X_test.toarray()\n",
        "encoder = LabelEncoder()\n",
        "y_test = encoder.fit_transform(y_test)\n",
        "# Define model\n",
        "#model = Sequential([\n",
        "#    Dense(505, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-8)),  # Input layer\n",
        "#    Dense(220, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-7)),  # Hidden layer\n",
        "#    Dense(len(label_mapping), activation='softmax')  # Output layer\n",
        "#])\n",
        "\n",
        "# Compile model\n",
        "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#epochs = 2\n",
        "#model.fit(X_train, y_train, validation_split=0.2, epochs=epochs)\n",
        "\n",
        "# Save the final model\n",
        "#model.save('NN_final_model_2.h5')\n",
        "\n",
        "# Load the final model\n",
        "loaded_model = load_model('NN_final_model_2.h5')\n",
        "\n",
        "\n",
        "# Evaluate the loaded model on the test set\n",
        "final_loss, final_accuracy = loaded_model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {final_loss:.4f}')\n",
        "print(f'Test Accuracy: {final_accuracy*100:.2f}%')"
      ],
      "id": "383e91bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word Embeddings \n"
      ],
      "id": "270bfe43"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tokenize sentences using white-space-based tokenization\n",
        "data['Tokenized_Sentences'] = data['Sentences'].apply(lambda x: x.split())\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=data['Tokenized_Sentences'], vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to calculate sentence embedding\n",
        "def sentence_embedding(sentence_tokens, model):\n",
        "    \"\"\"Calculate sentence embedding as the mean of the word embeddings.\"\"\"\n",
        "    embeddings = [model.wv[word] for word in sentence_tokens if word in model.wv.index_to_key]\n",
        "    return np.mean(embeddings, axis=0) if len(embeddings) > 0 else np.zeros(model.vector_size)\n",
        "\n",
        "# Create sentence embeddings\n",
        "data['Sentence_Embeddings'] = data['Tokenized_Sentences'].apply(lambda x: sentence_embedding(x, word2vec_model))\n",
        "\n",
        "# Encode the \"Presidents\" labels into numerical format\n",
        "label_mapping = {label: idx for idx, label in enumerate(data['Presidents'].unique())}\n",
        "data['Label'] = data['Presidents'].map(label_mapping)\n",
        "\n",
        "# Split data into features (X) and target (y)\n",
        "X = np.vstack(data['Sentence_Embeddings'].to_numpy())\n",
        "y = data['Label'].to_numpy()\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "id": "96214844",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy: 29.18%"
      ],
      "id": "fa046fcc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pool = Pool(data=X_train, label=y_train, cat_features=[])\n",
        "# Parameters for the CatBoostClassifier\n",
        "params = {\n",
        "    'iterations': 3000,          # Number of boosting iterations\n",
        "    'depth': 5,                # Depth of the trees\n",
        "    'learning_rate': 0.05,      # Learning rate\n",
        "    'loss_function': 'MultiClass',  # Objective function\n",
        "    'random_seed': 42,             # Random seed\n",
        "    'verbose': 10                   # Output training information every 10 iterations\n",
        "}\n",
        "\n",
        "#cv_results = cv(\n",
        " #   pool=pool,\n",
        " #   params=params,\n",
        " #   fold_count=5,  # Number of folds in CV\n",
        " #   plot=False,   # Set to True if you want to see the plot of train and test errors during cross-validation\n",
        "  #  early_stopping_rounds=10\n",
        "#)\n",
        "\n",
        "# Save cross-validation results to a CSV file\n",
        "#cv_results.to_csv('cv_results_over_epochs_3.csv', index=False)\n",
        "\n",
        "# Train the model on the full training set and save it\n",
        "#clf = CatBoostClassifier(**params)\n",
        "#clf.fit(pool)\n",
        "#clf.save_model('catboost_WordEmbed.cbm')\n",
        "\n",
        "# Load the model from the file\n",
        "loaded_model = CatBoostClassifier()\n",
        "loaded_model.load_model('catboost_WordEmbed.cbm')\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "y_pred_decoded = le.inverse_transform(y_pred.flatten().astype(int))\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred.flatten().astype(int))\n",
        "classification_rep = classification_report(y_test, y_pred.flatten().astype(int), target_names=le.classes_)\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print('Classification Report:')\n",
        "print(classification_rep)"
      ],
      "id": "d8a31323",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Read the CSV file\n",
        "new_df = pd.read_csv(\"cv_results_over_epochs_3.csv\")\n",
        "\n",
        "# Plotting the mean values for training and validation errors with distinct colors\n",
        "plt.plot(new_df['iterations'], new_df['train-MultiClass-mean'], label='Training Error', color='b')  \n",
        "plt.plot(new_df['iterations'], new_df['test-MultiClass-mean'], label='Validation Error', color='r')  \n",
        "\n",
        "# Adding title and labels to the plot\n",
        "plt.title('Training and Validation Error Over Epochs')\n",
        "plt.xlabel('Epochs (Iterations)')\n",
        "plt.ylabel('Error')\n",
        "\n",
        "# Adding legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "f057c875",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM\n"
      ],
      "id": "80a6a60b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],  # Type of SVM\n",
        "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
        "#}\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "#svm = SVC(random_state=42)\n",
        "\n",
        "# Initialize Grid Search\n",
        "#grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform Grid Search on the training data\n",
        "#grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best estimator from Grid Search\n",
        "#best_params = grid_search.best_params_\n",
        "#best_svm_clf = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions using the best model\n",
        "#y_pred_best_svm = best_svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "#accuracy_best_svm = accuracy_score(y_test, y_pred_best_svm)\n",
        "#classification_rep_best_svm = classification_report(y_test, y_pred_best_svm, target_names=label_mapping.keys())"
      ],
      "id": "bda722b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "39.64%"
      ],
      "id": "d9773d30"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize the Support Vector Machine classifier with specific parameters\n",
        "specific_svm_clf = SVC(kernel='linear', gamma='scale', C=10, random_state=42)\n",
        "\n",
        "# Fit the model on the training data\n",
        "specific_svm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred_specific_svm = specific_svm_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy_specific_svm = accuracy_score(y_test, y_pred_specific_svm)\n",
        "classification_rep_specific_svm = classification_report(y_test, y_pred_specific_svm, target_names=label_mapping.keys())\n",
        "\n",
        "# Print the accuracy and classification report\n",
        "print(f'Accuracy (Specific SVM): {accuracy_specific_svm * 100:.2f}%')\n",
        "print('Classification Report (Specific SVM):')\n",
        "print(classification_rep_specific_svm)"
      ],
      "id": "991bd994",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Network \n",
        "Accuracy: 36.69%\n"
      ],
      "id": "1f745742"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define model\n",
        "#model = Sequential([\n",
        " #   Dense(512, input_dim=X_train.shape[1], activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-2)),  # Input layer\n",
        "  #  Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-5)),  # Hidden layer\n",
        "  #  Dense(256, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-5)),  # Hidden layer\n",
        "  #  Dense(len(label_mapping), activation='softmax')  # Output layer\n",
        "#])\n",
        "\n",
        "# Compile model\n",
        "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Set early stopping and model checkpoint callbacks\n",
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "#model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "#callbacks = [early_stopping, model_checkpoint]\n",
        "\n",
        "# Train model\n",
        "#model.fit(X_train, y_train, validation_split=0.2, epochs=100, callbacks=callbacks)\n",
        "\n",
        "# Evaluate model\n",
        "#loss, accuracy = model.evaluate(X_test, y_test)\n",
        "#print(f'Loss: {loss:.4f}')\n",
        "#print(f'Accuracy: {accuracy*100:.2f}%')"
      ],
      "id": "193ecbb3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "firstenv",
      "language": "python",
      "display_name": "firstEnv"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}